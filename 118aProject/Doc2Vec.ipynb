{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of introvert comments are 3602\n",
      "# of extrovert comments are 2614\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Ecsv=pd.read_csv('Edata.csv')  \n",
    "Icsv=pd.read_csv('Idata.csv') \n",
    "EIcsv=pd.concat([Ecsv,Icsv])\n",
    "rowInd=pd.Series(range(len(EIcsv)))\n",
    "EIcsv=EIcsv.set_index(rowInd)\n",
    "EIcsv=EIcsv.drop(['Unnamed: 0'],axis=1) #raw comments with labels as a dataframe\n",
    "print('# of introvert comments are',Icsv.shape[0])\n",
    "print('# of extrovert comments are',Ecsv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize sklearn models with balanced weight(unbalanced dataset)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(class_weight='balanced')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randfor= RandomForestClassifier(class_weight='balanced')\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC(kernel='linear',class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english') ##initialize stopwords to remove\n",
    "stopwords= r'\\b(?:{})\\b'.format('|'.join(stop))\n",
    "\n",
    "def FeatVect(model, input_docs):\n",
    "    sentences = input_docs\n",
    "    feature_vectors = [model.infer_vector(doc.words, steps=20) for doc in sentences]\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##initialize parameter grids for different models for cv\n",
    "from scipy.stats import uniform\n",
    "logreg_grid=dict(C=uniform(loc=0, scale=4),penalty=['l2', 'l1'],solver=['liblinear','saga'])\n",
    "neigh_grid = {'n_neighbors': np.arange(1, 8), 'weights': ['uniform','distance']}\n",
    "svm_grid=dict(C=[.01,4],gamma=[.01,1]) #randomizedsearch samples uniformly \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Data via Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIcsv['text']=EIcsv.loc[:,'text'].str.replace(stopwords, '') #remove stop words\n",
    "EIcsv['text']=EIcsv.loc[:,'text'].str.replace(r'[^\\w\\s]', '') #removed punctuation\n",
    "EIcsv_tuple=[tuple(x) for x in EIcsv.to_records(index=False)] #turn into tuples\n",
    "EIcsv_tagged=[TaggedDocument(words=word_tokenize(text.lower()), tags=[str(label)]) #creating tagged-document\n",
    "    for label,text in EIcsv_tuple]\n",
    "docvec = Doc2Vec(dm=1, vector_size=100, hs=0, min_count=2, sample = 0, alpha=0.025, min_alpha=0.001) #dimensions=100\n",
    "docvec.build_vocab(EIcsv_tagged) \n",
    "docvec.train(EIcsv_tagged,total_examples=len(EIcsv_tagged), epochs=15) #training docvec model\n",
    "EIdata=FeatVect(docvec,EIcsv_tagged) ##getting feature vectors now\n",
    "EIlabels=EIcsv.iloc[:,0] #turn back into dataframe with labels so we can train,test,split\n",
    "EIdf=pd.DataFrame(EIdata)\n",
    "EIdf['label']=EIlabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over Training Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=14. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "trials=[1,2,3]\n",
    "splits=[0.8,0.5,0.2]\n",
    "models=[logreg,neigh,svm]\n",
    "test_scores=[]\n",
    "valid_scores=[]\n",
    "train_scores=[]\n",
    "for model in models:\n",
    "    if model is logreg:\n",
    "        param_grid=logreg_grid\n",
    "    elif model is neigh:\n",
    "        param_grid=neigh_grid\n",
    "    else:\n",
    "        param_grid=svm_grid\n",
    "    for split in splits:\n",
    "        for trial in trials:\n",
    "            shuffled_data=shuffle(EIdf, random_state=trial)\n",
    "            train, test= train_test_split(shuffled_data,test_size=split,random_state=trial)\n",
    "            test_labels=test.iloc[:,-1]  \n",
    "            train_labels=train.iloc[:,-1]\n",
    "            train_vect=train.iloc[:,:-1]\n",
    "            test_vect=test.iloc[:,:-1]\n",
    "            trainMod=model.fit(train_vect,train_labels) #train model without cv\n",
    "            TrainScore=trainMod.score(train_vect,train_labels)\n",
    "            train_scores.append(TrainScore)\n",
    "            RndSrch = RandomizedSearchCV(model, param_grid, n_iter=14, cv=5,n_jobs=6) #cross-validate\n",
    "            tuned=RndSrch.fit(train_vect,train_labels)\n",
    "            valid_scores.append(max(tuned.cv_results_['mean_test_score']))\n",
    "            BestParams =tuned.best_params_\n",
    "            TrainTuned=model.set_params(**BestParams)  #train model using tuned parameters from cv\n",
    "            TrainTuned.fit(train_vect,train_labels)\n",
    "            pred_labels=TrainTuned.predict(test_vect)  #test model using tuned parameters \n",
    "            test_scores.append(accuracy_score(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Train  Validation      Test\n",
      "LogReg  0.833221    0.828691  0.833130\n",
      "KNN     0.849302    0.758281  0.756420\n",
      "SVM     0.832547    0.824784  0.830814\n",
      "Best model for train dataset is ['KNN']\n",
      "Best model for validation dataset is ['LogReg']\n",
      "Best model for test dataset is ['LogReg']\n"
     ]
    }
   ],
   "source": [
    "## 3 models, 3 partitions, 3 trials is 27 scores per type of score\n",
    "#scores 0-8: logreg, scores 9-17: neigh, scores 18-26: svm\n",
    "from statistics import mean\n",
    "TrAvgs=[mean(train_scores[0:8]),mean(train_scores[9:17]),mean(train_scores[18:26])]\n",
    "ValAvgs=[mean(valid_scores[0:8]), mean(valid_scores[9:17]),mean(valid_scores[18:26])] \n",
    "TestAvgs=[mean(test_scores[0:8]),mean(test_scores[9:17]),mean(test_scores[18:26])]\n",
    "\n",
    "averages=pd.DataFrame(list(zip(TrAvgs,ValAvgs,TestAvgs)),index=['LogReg','KNN','SVM'],columns=['Train','Validation','Test'])\n",
    "print(averages)\n",
    "print('Best model for train dataset is',list(averages.index[averages.Train==max(averages.Train)]))\n",
    "print('Best model for validation dataset is',list(averages.index[averages.Validation==max(averages.Validation)]))\n",
    "print('Best model for test dataset is',list(averages.index[averages.Test==max(averages.Test)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest for Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for RandFor is: 0.999597747385358\n",
      "Best Validation score for RandFor is 0.8131536604987932\n",
      "Tuned test score for RandFor is: 0.8279742765273312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "train, test= train_test_split(EIdf,test_size=0.2,random_state=1) #train,test split\n",
    "test_labels=test.iloc[:,-1]  \n",
    "train_labels=train.iloc[:,-1]\n",
    "train_vect=train.iloc[:,:-1]\n",
    "test_vect=test.iloc[:,:-1]\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True,False],\n",
    "    'max_depth': [10,50,100,150,200],\n",
    "    'n_estimators': [100, 200, 500, 1000]}\n",
    "\n",
    "\n",
    "trainMod=randfor.fit(train_vect,train_labels)\n",
    "train_score=trainMod.score(train_vect,train_labels)\n",
    "RndSrch = RandomizedSearchCV(randfor, param_grid,cv = 5, n_jobs=6)\n",
    "tuned=RndSrch.fit(train_vect,train_labels)\n",
    "val_score=max(tuned.cv_results_['mean_test_score'])\n",
    "BestParams=tuned.best_params_\n",
    "TrainTuned=randfor.set_params(**BestParams)\n",
    "TrainTuned.fit(train_vect,train_labels)\n",
    "pred_labels=TrainTuned.predict(test_vect)\n",
    "\n",
    "print('Training score for RandFor is:',train_score)\n",
    "print('Best Validation score for RandFor is', val_score)\n",
    "test_score=accuracy_score(pred_labels,test_labels)\n",
    "print('Tuned test score for RandFor is:',test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
